#!/usr/bin/env python3
"""
–û—Ü–µ–Ω–∫–∞ LLM-as-Judge –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
"""

import json
import random
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from llm_as_judge_prototype import LLMJudge, load_few_shot_examples
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


def evaluate_on_dataset(dataset_path: str = "ltr_dataset.json",
                        num_eval_samples: int = 20,
                        num_few_shot: int = 5):
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç LLM-as-Judge –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞

    Args:
        dataset_path: –ü—É—Ç—å –∫ —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
        num_eval_samples: –°–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        num_few_shot: –°–∫–æ–ª—å–∫–æ few-shot –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
    """

    print("=" * 70)
    print("üìä –û—Ü–µ–Ω–∫–∞ LLM-as-Judge –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ")
    print("=" * 70)
    print()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    labeled = [item for item in data if item.get('label') is not None]
    print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç: {len(labeled)} —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    print()

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ few-shot –∏ eval
    random.seed(42)
    random.shuffle(labeled)

    few_shot_data = labeled[:num_few_shot]
    eval_data = labeled[num_few_shot:num_few_shot + num_eval_samples]

    print(f"üìö Few-shot: {num_few_shot} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"üéØ –û—Ü–µ–Ω–∫–∞ –Ω–∞: {len(eval_data)} –ø—Ä–∏–º–µ—Ä–∞—Ö")
    print()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É–¥—å—é
    judge = LLMJudge()

    # –û—Ü–µ–Ω–∏–≤–∞–µ–º
    y_true = []
    y_pred = []

    print("üîÑ –û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)...")
    print()

    for i, item in enumerate(eval_data, 1):
        query = item['query']
        title = item.get('title', '')
        description = item.get('description', '')
        true_label = item['label']

        print(f"[{i}/{len(eval_data)}] {query[:40]}... ", end='', flush=True)

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred_label = judge.judge(
            query=query,
            news_title=title,
            news_description=description,
            few_shot_examples=few_shot_data
        )

        if pred_label is not None:
            y_true.append(true_label)
            y_pred.append(pred_label)

            match = "‚úì" if pred_label == true_label else "‚úó"
            print(f"(–∏—Å—Ç–∏–Ω–∞: {true_label}, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {pred_label}) {match}")
        else:
            print("‚ö†Ô∏è –û–®–ò–ë–ö–ê")

    print()
    print("=" * 70)

    # –ú–µ—Ç—Ä–∏–∫–∏
    if y_true:
        accuracy = accuracy_score(y_true, y_pred)
        print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy * 100:.1f}%")
        print()

        print("üìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])
        print("   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ ‚Üí")
        print("   ", "  0   1   2   3")
        for i, row in enumerate(cm):
            print(f"{i}  {row}")
        print()

        print("üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç:")
        print(classification_report(y_true, y_pred,
                                   labels=[0, 1, 2, 3],
                                   target_names=['0 (–Ω–µ—Ä–µ–ª–µ–≤)', '1 (—Å–ª–∞–±–æ)', '2 (—Ä–µ–ª–µ–≤)', '3 (–∏–¥–µ–∞–ª)']))

    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

    print("=" * 70)


if __name__ == "__main__":
    evaluate_on_dataset(
        num_eval_samples=20,  # –ù–∞—á–Ω–µ–º —Å 20 –ø—Ä–∏–º–µ—Ä–æ–≤
        num_few_shot=4
    )
