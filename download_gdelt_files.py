#!/usr/bin/env python3
"""
–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—ã—Ä—ã—Ö GDELT GKG —Ñ–∞–π–ª–æ–≤ (–ë–ï–ó rate limits!)

GKG (Global Knowledge Graph) —Å–æ–¥–µ—Ä–∂–∏—Ç:
- URLs —Å—Ç–∞—Ç–µ–π
- –¢–µ–º—ã, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –ª—é–¥–∏, –ª–æ–∫–∞—Ü–∏–∏
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
- –Ø–∑—ã–∫ –∏ —Å—Ç—Ä–∞–Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- –ù–µ—Ç API rate limits
- –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ —Ç–æ–ª—å–∫–æ 250 —Å—Ç–∞—Ç–µ–π)
- –ú–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –∑–∞ –ª—é–±–æ–π –ø–µ—Ä–∏–æ–¥

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python3 download_gdelt_files.py --start-date 2024-09-01 --end-date 2024-10-31
"""

import requests
import zipfile
import shutil
import csv
import os
import sys
from datetime import datetime, timedelta
import argparse
from typing import List
import time

# GDELT v2 master file list
MASTER_LIST_URL = "http://data.gdeltproject.org/gdeltv2/masterfilelist.txt"


def get_available_files(start_date: datetime, end_date: datetime,
                        hours_interval: int = 24) -> List[str]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GDELT —Ñ–∞–π–ª–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥

    Args:
        start_date: –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        end_date: –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
        hours_interval: –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –≤ —á–∞—Å–∞—Ö (24 = 1 —Ñ–∞–π–ª –≤ –¥–µ–Ω—å)

    Returns:
        –°–ø–∏—Å–æ–∫ URL —Ñ–∞–π–ª–æ–≤ .gkg.csv.zip
    """
    print("üîç –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GDELT —Ñ–∞–π–ª–æ–≤...")

    try:
        response = requests.get(MASTER_LIST_URL, timeout=30)
        response.raise_for_status()
        lines = response.text.strip().split('\n')
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ masterfilelist: {e}")
        return []

    # –§–∏–ª—å—Ç—Ä—É–µ–º GKG —Ñ–∞–π–ª—ã –∑–∞ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥
    selected_files = []
    current = start_date

    while current <= end_date:
        # –ò—â–µ–º —Ñ–∞–π–ª –¥–ª—è —ç—Ç–æ–≥–æ –¥–Ω—è (–±–µ—Ä–µ–º –ø–æ–ª–¥–µ–Ω—å 12:00)
        target_time = current.replace(hour=12, minute=0, second=0)
        timestamp = target_time.strftime("%Y%m%d%H%M%S")

        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π —Ñ–∞–π–ª
        for line in lines:
            if timestamp in line and '.gkg.csv.zip' in line:
                parts = line.split()
                if len(parts) >= 3:
                    url = parts[2]
                    selected_files.append(url)
                    break

        current += timedelta(hours=hours_interval)

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(selected_files)} —Ñ–∞–π–ª–æ–≤")
    return selected_files


def download_and_extract_file(url: str, output_dir: str) -> str:
    """
    –°–∫–∞—á–∞—Ç—å –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å GDELT —Ñ–∞–π–ª

    Args:
        url: URL —Ñ–∞–π–ª–∞
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

    Returns:
        –ü—É—Ç—å –∫ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–º—É CSV —Ñ–∞–π–ª—É
    """
    filename = url.split('/')[-1]
    zip_path = os.path.join(output_dir, filename)
    csv_path = zip_path.replace('.zip', '')

    # –°–∫–∞—á–∏–≤–∞–µ–º
    try:
        print(f"   üì• –°–∫–∞—á–∏–≤–∞—é {filename}...")
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()

        with open(zip_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        file_size = os.path.getsize(zip_path) / (1024 * 1024)
        print(f"   ‚úÖ –°–∫–∞—á–∞–Ω–æ: {file_size:.1f} MB")

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
        return None

    # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
    try:
        print(f"   üì¶ –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞—é...")

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # ZIP —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª - –∏–∑–≤–ª–µ–∫–∞–µ–º –µ–≥–æ
            names = zip_ref.namelist()
            if names:
                zip_ref.extract(names[0], output_dir)
                extracted_path = os.path.join(output_dir, names[0])

                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –≤ –æ–∂–∏–¥–∞–µ–º–æ–µ –∏–º—è
                if extracted_path != csv_path:
                    if os.path.exists(csv_path):
                        os.remove(csv_path)
                    os.rename(extracted_path, csv_path)

        # –£–¥–∞–ª—è–µ–º zip
        os.remove(zip_path)

        unzipped_size = os.path.getsize(csv_path) / (1024 * 1024)
        print(f"   ‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∞–Ω–æ: {unzipped_size:.1f} MB")

        return csv_path

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {e}")
        return None


def filter_gkg_file(input_csv: str, output_csv: str,
                    language: str = None, country: str = None) -> int:
    """
    –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å GKG —Ñ–∞–π–ª –ø–æ —è–∑—ã–∫—É/—Å—Ç—Ä–∞–Ω–µ

    GKG —Ñ–æ—Ä–º–∞—Ç (27 –∫–æ–ª–æ–Ω–æ–∫):
    0: GKGRECORDID
    1: DATE
    2: SourceCollectionIdentifier
    3: SourceCommonName
    4: DocumentIdentifier (URL)
    ...

    Args:
        input_csv: –≤—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª
        output_csv: –≤—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª
        language: —Ñ–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É
        country: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞–Ω–µ

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    """
    count = 0

    try:
        with open(input_csv, 'r', encoding='utf-8', errors='ignore') as f_in:
            with open(output_csv, 'a', newline='', encoding='utf-8') as f_out:
                reader = csv.reader(f_in, delimiter='\t')
                writer = csv.writer(f_out)

                for row in reader:
                    if len(row) < 5:
                        continue

                    # –ö–æ–ª–æ–Ω–∫–∞ 4 - DocumentIdentifier (URL)
                    url = row[4] if len(row) > 4 else ''

                    # –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —è–∑—ã–∫—É/—Å—Ç—Ä–∞–Ω–µ —á–µ—Ä–µ–∑ URL
                    # (–í GKG –Ω–µ—Ç –ø—Ä—è–º—ã—Ö –ø–æ–ª–µ–π language/country, –æ–Ω–∏ –≤—ã–≤–æ–¥—è—Ç—Å—è –∏–∑ –¥—Ä—É–≥–∏—Ö –¥–∞–Ω–Ω—ã—Ö)

                    if language:
                        # –ò—â–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –≤ URL –∏–ª–∏ –¥–æ–º–µ–Ω–µ
                        if language.lower() == 'russian':
                            if not any(domain in url.lower() for domain in ['.ru/', '.—Ä—Ñ/', 'russian', 'russia']):
                                continue

                    if country:
                        if country.lower() == 'russia':
                            if not any(domain in url.lower() for domain in ['.ru/', '.—Ä—Ñ/']):
                                continue

                    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å: date, url, source
                    simple_row = [
                        row[1] if len(row) > 1 else '',  # DATE
                        row[4] if len(row) > 4 else '',  # URL
                        row[3] if len(row) > 3 else '',  # SourceCommonName
                    ]

                    writer.writerow(simple_row)
                    count += 1

        # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        os.remove(input_csv)

    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}")

    return count


def download_gdelt_period(start_date: datetime, end_date: datetime,
                          language: str = None, country: str = None,
                          output_dir: str = "gdelt_raw_data",
                          hours_interval: int = 24) -> int:
    """
    –°–∫–∞—á–∞—Ç—å GDELT —Ñ–∞–π–ª—ã –∑–∞ –ø–µ—Ä–∏–æ–¥

    Args:
        start_date: –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        end_date: –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
        language: —Ñ–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É
        country: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞–Ω–µ
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        hours_interval: –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –≤ —á–∞—Å–∞—Ö

    Returns:
        –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
    """
    os.makedirs(output_dir, exist_ok=True)

    print("=" * 70)
    print("üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—ã—Ä—ã—Ö GDELT —Ñ–∞–π–ª–æ–≤")
    print("=" * 70)
    print(f"\nüìÖ –ü–µ—Ä–∏–æ–¥: {start_date.strftime('%Y-%m-%d')} ‚Üí {end_date.strftime('%Y-%m-%d')}")
    print(f"üóÇÔ∏è  –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}/")
    print(f"‚è±Ô∏è  –ò–Ω—Ç–µ—Ä–≤–∞–ª: {hours_interval} —á–∞—Å–æ–≤ ({24 // hours_interval} —Ñ–∞–π–ª–æ–≤ –≤ –¥–µ–Ω—å)")

    if language:
        print(f"üåê –§–∏–ª—å—Ç—Ä —è–∑—ã–∫–∞: {language}")
    if country:
        print(f"üåç –§–∏–ª—å—Ç—Ä —Å—Ç—Ä–∞–Ω—ã: {country}")

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
    file_urls = get_available_files(start_date, end_date, hours_interval)

    if not file_urls:
        print("\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")
        return 0

    print(f"\nüìä –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é: {len(file_urls)}")

    # –û—Ü–µ–Ω–∫–∞ –æ–±—ä–µ–º–∞
    avg_file_size = 10  # MB –≤ —Å—Ä–µ–¥–Ω–µ–º (—Å–∂–∞—Ç—ã–π)
    total_size = len(file_urls) * avg_file_size
    print(f"üìè –ü—Ä–∏–º–µ—Ä–Ω—ã–π –æ–±—ä–µ–º: ~{total_size:.0f} MB —Å–∂–∞—Ç—ã—Ö, ~{total_size * 10:.0f} MB —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã—Ö")
    print(f"‚è≥ –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~{len(file_urls) * 0.5:.0f} –º–∏–Ω—É—Ç")

    print("\n" + "=" * 70)
    print("‚è≥ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ...")
    print("=" * 70)

    # –ò—Ç–æ–≥–æ–≤—ã–π CSV —Ñ–∞–π–ª
    output_csv = os.path.join(
        output_dir,
        f"gdelt_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.csv"
    )

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    with open(output_csv, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['date', 'url', 'source'])

    total_records = 0

    for i, url in enumerate(file_urls, 1):
        print(f"\nüì¶ –§–∞–π–ª {i}/{len(file_urls)}: {url.split('/')[-1]}")

        # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
        csv_path = download_and_extract_file(url, output_dir)

        if not csv_path:
            continue

        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
        print(f"   üîç –§–∏–ª—å—Ç—Ä—É—é...")
        count = filter_gkg_file(csv_path, output_csv, language, country)
        total_records += count
        print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {count:,}")

        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
        if i < len(file_urls):
            time.sleep(1)

    print("\n" + "=" * 70)
    print("‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("=" * 70)
    print(f"\nüìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")

    if total_records > 0:
        file_size = os.path.getsize(output_csv) / (1024 * 1024)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_csv}")
        print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.1f} MB")

    return total_records


def main():
    parser = argparse.ArgumentParser(
        description="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—ã—Ä—ã—Ö GDELT GKG —Ñ–∞–π–ª–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ó–∞ 2 –º–µ—Å—è—Ü–∞ (–ø–æ 1 —Ñ–∞–π–ª—É –≤ –¥–µ–Ω—å)
  python3 download_gdelt_files.py --start-date 2024-09-01 --end-date 2024-10-31

  # –° —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –†–æ—Å—Å–∏–∏
  python3 download_gdelt_files.py --start-date 2024-09-01 --end-date 2024-10-31 --language Russian

  # –ë–æ–ª—å—à–µ —Ñ–∞–π–ª–æ–≤ (–∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤)
  python3 download_gdelt_files.py --start-date 2024-10-01 --end-date 2024-10-31 --interval 6
        """
    )

    parser.add_argument("--start-date", required=True, help="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)")
    parser.add_argument("--end-date", required=True, help="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)")
    parser.add_argument("--language", help="–§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É (Russian, English, etc)")
    parser.add_argument("--country", help="–§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞–Ω–µ (Russia, US, etc)")
    parser.add_argument("--output-dir", default="gdelt_raw_data", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    parser.add_argument("--interval", type=int, default=24,
                       help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –≤ —á–∞—Å–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 24)")

    args = parser.parse_args()

    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã
    start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
    end_date = datetime.strptime(args.end_date, "%Y-%m-%d")

    # –°–∫–∞—á–∏–≤–∞–µ–º
    try:
        total = download_gdelt_period(
            start_date=start_date,
            end_date=end_date,
            language=args.language,
            country=args.country,
            output_dir=args.output_dir,
            hours_interval=args.interval
        )

        print("\nüéâ –ì–æ—Ç–æ–≤–æ!")

        if total == 0:
            print("\n‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")

        return 0

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
