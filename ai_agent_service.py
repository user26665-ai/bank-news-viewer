#!/usr/bin/env python3
"""
AI Agent Service (–ë–ï–ó –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞)
- –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ API –ø–µ—Ä–≤–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
- –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª–æ–∫–∞–ª—å–Ω—ã–º LLM (Qwen)
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã

–ó–∞–ø—É—Å–∫: python3 ai_agent_service.py
API: http://localhost:8002
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import requests
from datetime import datetime

app = FastAPI(title="AI Agent API", version="1.0")

# –î–æ–±–∞–≤–ª—è–µ–º CORS middleware –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –†–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
NEWS_COLLECTOR_URL = "http://localhost:8001"
LM_STUDIO_API_URL = "http://localhost:1234/v1/chat/completions"

class QueryRequest(BaseModel):
    question: str
    top_k: int = 15

class NewsItem(BaseModel):
    title: str
    description: str
    link: str
    source: str
    published: str
    similarity: float
    critical_keywords: Optional[int] = 0

class AgentResponse(BaseModel):
    question: str
    answer: str
    news_found: int
    top_news: List[NewsItem]
    timestamp: str

def get_news_from_collector(query: str, top_k: int = 15) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç News Collector —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        response = requests.post(
            f"{NEWS_COLLECTOR_URL}/search",
            json={"query": query, "top_k": top_k},
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        raise HTTPException(
            status_code=503,
            detail="News Collector Service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python3 news_collector_service.py"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {str(e)}")

def hide_reasoning_under_spoiler(text: str) -> str:
    """
    –û–±–µ—Ä–Ω—É—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ markdown —Å–ø–æ–π–ª–µ—Ä

    –ò—â–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤ <details>
    """
    import re

    # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –¢–µ–≥–∏ <think> –∏–ª–∏ <reasoning>
    if '<think>' in text.lower() or '<reasoning>' in text.lower():
        text = re.sub(
            r'<think>(.*?)</think>',
            r'<details>\n<summary>üí≠ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</summary>\n\n\1\n</details>\n\n',
            text,
            flags=re.DOTALL | re.IGNORECASE
        )
        text = re.sub(
            r'<reasoning>(.*?)</reasoning>',
            r'<details>\n<summary>üí≠ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</summary>\n\n\1\n</details>\n\n',
            text,
            flags=re.DOTALL | re.IGNORECASE
        )

    # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –í—Å—ë –¥–æ "–û—Ç–≤–µ—Ç:", "–ò—Ç–æ–≥–æ:", "–í—ã–≤–æ–¥:"
    reasoning_patterns = [
        (r'(.*?)(–û—Ç–≤–µ—Ç:|–ò—Ç–æ–≥–æ:|–í—ã–≤–æ–¥:|–ó–∞–∫–ª—é—á–µ–Ω–∏–µ:)', 2),
        (r'(.*?)(–ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏|–ò—Å—Ö–æ–¥—è –∏–∑)', 2),
    ]

    for pattern, min_group in reasoning_patterns:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            reasoning = match.group(1).strip()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (> 80 —Å–∏–º–≤–æ–ª–æ–≤)
            if len(reasoning) > 80:
                rest_of_text = text[len(match.group(1)):].strip()
                text = f"<details>\n<summary>üí≠ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</summary>\n\n{reasoning}\n</details>\n\n{rest_of_text}"
                break

    return text

def query_llm(user_question: str, relevant_news: list) -> str:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É LLM"""

    news_context = "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞–Ω–∫–∞):\n\n"
    for i, news in enumerate(relevant_news, 1):
        news_context += f"{i}. {news['title']}\n"
        news_context += f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {news['source']}\n"
        news_context += f"   –û–ø–∏—Å–∞–Ω–∏–µ: {news['description']}\n"
        news_context += f"   –î–∞—Ç–∞: {news['published']}\n"
        news_context += f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {news['similarity']:.2%}"
        if news.get('critical_keywords', 0) > 0:
            news_context += f" ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û (—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {news['critical_keywords']})"
        news_context += "\n\n"

    system_prompt = """–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –±–∞–Ω–∫–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö.
–¢–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, –û–¢–°–û–†–¢–ò–†–û–í–ê–ù–ù–´–ï –ü–û –í–ê–ñ–ù–û–°–¢–ò –î–õ–Ø –ë–ê–ù–ö–û–í–°–ö–û–ì–û –°–ï–ö–¢–û–†–ê.

–í–ê–ñ–ù–û:
- –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –æ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –≤–æ–ø—Ä–æ—Å—É)
- –ï—Å–ª–∏ –≤ –Ω–æ–≤–æ—Å—Ç—è—Ö –ï–°–¢–¨ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–π –µ–µ –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å
- –ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç–∏ —Å –º–µ—Ç–∫–æ–π ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û - —ç—Ç–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ-–∑–Ω–∞—á–∏–º—ã–µ —Å–æ–±—ã—Ç–∏—è
- –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞: —Å–∞–Ω–∫—Ü–∏—è—Ö, –≤–∞–ª—é—Ç–µ, –¶–ë, –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö —Å—Ç–∞–≤–∫–∞—Ö, –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö —Ä–∏—Å–∫–∞—Ö
- –ï—Å–ª–∏ –≤ –Ω–æ–≤–æ—Å—Ç—è—Ö –ù–ï–¢ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å—É - –Ω–∞–ø–∏—à–∏ "–≠—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö, –Ω–æ..." –∏ –¥–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–∏—Ö –∑–Ω–∞–Ω–∏–π
- –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã, –∫–æ–º–ø–∞–Ω–∏–∏
- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""

    user_prompt = f"{news_context}\n\n–í–æ–ø—Ä–æ—Å: {user_question}\n\n–û—Ç–≤–µ—Ç:"

    payload = {
        "model": "qwen3-8b",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Qwen3 8B
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.2,
        "max_tokens": 2000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        "stream": False
    }

    try:
        response = requests.post(LM_STUDIO_API_URL, json=payload, timeout=120)
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()

            # –ü—Ä—è—á–µ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ–¥ —Å–ø–æ–π–ª–µ—Ä
            answer = hide_reasoning_under_spoiler(answer)

            return answer
        else:
            return f"–û—à–∏–±–∫–∞ LLM API: {response.status_code}"
    except requests.exceptions.ConnectionError:
        raise HTTPException(
            status_code=503,
            detail="LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ LM Studio —Å –º–æ–¥–µ–ª—å—é Qwen3 8B"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ LLM: {str(e)}")

@app.on_event("startup")
async def startup_event():
    print("=" * 70)
    print("ü§ñ AI Agent Service –∑–∞–ø—É—â–µ–Ω")
    print(f"üì° API: http://localhost:8002")
    print(f"üìñ Docs: http://localhost:8002/docs")
    print(f"üîó News Collector: {NEWS_COLLECTOR_URL}")
    print(f"üß† LLM: {LM_STUDIO_API_URL}")
    print("=" * 70)

@app.get("/")
async def root():
    return {
        "service": "AI Agent API",
        "version": "1.0",
        "status": "running",
        "docs": "/docs",
        "dependencies": {
            "news_collector": NEWS_COLLECTOR_URL,
            "llm": LM_STUDIO_API_URL
        }
    }

@app.get("/health")
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    status = {"service": "healthy", "dependencies": {}}

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ News Collector
    try:
        response = requests.get(f"{NEWS_COLLECTOR_URL}/health", timeout=5)
        status["dependencies"]["news_collector"] = "healthy" if response.status_code == 200 else "unhealthy"
    except:
        status["dependencies"]["news_collector"] = "unavailable"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ LM Studio
    try:
        response = requests.get(f"{LM_STUDIO_API_URL.replace('/v1/chat/completions', '/v1/models')}", timeout=5)
        status["dependencies"]["llm"] = "healthy" if response.status_code == 200 else "unhealthy"
    except:
        status["dependencies"]["llm"] = "unavailable"

    return status

@app.post("/ask", response_model=AgentResponse)
async def ask_question(request: QueryRequest):
    """
    –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞–≥–µ–Ω—Ç—É

    –ü—Ä–æ—Ü–µ—Å—Å:
    1. –ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç News Collector
    2. –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π LLM
    3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç
    """

    # 1. –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞
    search_result = get_news_from_collector(request.question, request.top_k)

    if not search_result['news']:
        return AgentResponse(
            question=request.question,
            answer="–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ë–∞–∑–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–∞.",
            news_found=0,
            top_news=[],
            timestamp=datetime.now().isoformat()
        )

    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM
    answer = query_llm(request.question, search_result['news'])

    # 3. –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–æ–ø-5 –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞
    top_news = [
        NewsItem(
            title=item['title'],
            description=item['description'],
            link=item['link'],
            source=item['source'],
            published=item['published'],
            similarity=item['similarity'],
            critical_keywords=item.get('critical_keywords', 0)
        )
        for item in search_result['news'][:5]
    ]

    return AgentResponse(
        question=request.question,
        answer=answer,
        news_found=len(search_result['news']),
        top_news=top_news,
        timestamp=datetime.now().isoformat()
    )

@app.get("/collector/stats")
async def get_collector_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç News Collector"""
    try:
        response = requests.get(f"{NEWS_COLLECTOR_URL}/stats", timeout=5)
        response.raise_for_status()
        return response.json()
    except:
        raise HTTPException(status_code=503, detail="News Collector –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8002,
        log_level="info"
    )
