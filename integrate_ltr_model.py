#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è LTR –º–æ–¥–µ–ª–∏ –≤ NewsRAGSystem
"""

import pickle
import numpy as np
from news_rag_system import NewsRAGSystem
from typing import List, Dict


class LTRNewsRAGSystem(NewsRAGSystem):
    """RAG —Å–∏—Å—Ç–µ–º–∞ —Å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ LTR –º–æ–¥–µ–ª—å"""

    def __init__(self, ltr_model_path='ltr_model.pkl'):
        super().__init__()

        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î (–¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ NER-—Å—É—â–Ω–æ—Å—Ç—è–º)
        import sqlite3
        self.conn = sqlite3.connect(self.db_path)
        self.cursor = self.conn.cursor()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º LTR –º–æ–¥–µ–ª—å
        with open(ltr_model_path, 'rb') as f:
            model_data = pickle.load(f)

        self.ltr_model = model_data['model']
        self.feature_columns = model_data['feature_columns']

        print(f"‚úì LTR –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {ltr_model_path}")
        print(f"  –§–∏—á–∏: {', '.join(self.feature_columns)}")

    def calculate_features(self, query: str, news: Dict) -> Dict:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ñ–∏—á–∏ –¥–ª—è –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ ltr_dataset_generator)"""

        features = {}

        # 1. Embedding similarity
        features['embedding_score'] = news.get('similarity', 0.0)

        # 2. BM25 score (–∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è)
        features['bm25_score'] = self._calculate_bm25_approx(query, news)

        # 3. NER overlap
        features['ner_overlap'] = self._calculate_ner_overlap(query, news['id'])

        # 4. Morphological match
        features['morpho_match'] = self._calculate_morpho_match(query, news)

        # 5. Title match
        features['title_match'] = self._calculate_title_match(query, news['title'])

        # 6. Exact match
        features['exact_match'] = 1.0 if query.lower() in news['title'].lower() else 0.0

        # 7. Date recency
        features['days_ago'] = self._calculate_days_ago(news.get('published', ''))

        # 8. Source authority
        features['source_authority'] = self._get_source_authority(news.get('source', ''))

        # 9. Text length
        title_len = len(news.get('title', ''))
        desc_len = len(news.get('description', ''))
        features['text_length'] = title_len + desc_len

        return features

    def _calculate_bm25_approx(self, query: str, news: Dict) -> float:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è BM25"""
        query_words = set(query.lower().split())
        text = f"{news.get('title', '')} {news.get('description', '')}".lower()

        matches = sum(1 for word in query_words if word in text)
        return matches / len(query_words) if query_words else 0.0

    def _calculate_ner_overlap(self, query: str, news_id: int) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö NER-—Å—É—â–Ω–æ—Å—Ç–µ–π"""
        query_entities = self.ner_extractor.extract_from_news(query, "")
        query_ner_set = set(e['normalized'].lower() for e in query_entities['all'])

        if not query_ner_set:
            return 0.0

        self.cursor.execute('''
            SELECT normalized_text FROM entities WHERE news_id = ?
        ''', (news_id,))

        news_ner_set = set(row[0].lower() for row in self.cursor.fetchall() if row[0])

        if not news_ner_set:
            return 0.0

        intersection = query_ner_set & news_ner_set
        union = query_ner_set | news_ner_set

        return len(intersection) / len(union) if union else 0.0

    def _calculate_morpho_match(self, query: str, news: Dict) -> float:
        """–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"""
        import pymorphy2
        morph = pymorphy2.MorphAnalyzer()

        query_words = query.lower().split()
        text = f"{news.get('title', '')} {news.get('description', '')}".lower()

        matches = 0
        for word in query_words:
            parsed = morph.parse(word)[0]
            normal_form = parsed.normal_form

            if normal_form in text or word in text:
                matches += 1

        return matches / len(query_words) if query_words else 0.0

    def _calculate_title_match(self, query: str, title: str) -> float:
        """–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º"""
        query_words = set(query.lower().split())
        title_words = set(title.lower().split())

        if not query_words:
            return 0.0

        matches = query_words & title_words
        return len(matches) / len(query_words)

    def _calculate_days_ago(self, published: str) -> float:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥"""
        if not published:
            return 999.0

        try:
            from datetime import datetime
            from email.utils import parsedate_to_datetime

            if published.startswith(('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')):
                pub_date = parsedate_to_datetime(published)
            else:
                pub_date = datetime.fromisoformat(published.replace('Z', '+00:00'))

            now = datetime.now(pub_date.tzinfo)
            delta = (now - pub_date).days
            return max(0, delta)
        except:
            return 999.0

    def _get_source_authority(self, source: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        high_authority = ['–†–ë–ö', '–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç—ä', '–í–µ–¥–æ–º–æ—Å—Ç–∏', '–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å', '–¢–ê–°–°']
        medium_authority = ['–ò–∑–≤–µ—Å—Ç–∏—è', '–†–æ—Å—Å–∏–π—Å–∫–∞—è –≥–∞–∑–µ—Ç–∞', 'Banki.ru']

        for auth_source in high_authority:
            if auth_source.lower() in source.lower():
                return 1.0

        for auth_source in medium_authority:
            if auth_source.lower() in source.lower():
                return 0.5

        return 0.0

    def search_similar(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ LTR –º–æ–¥–µ–ª—å

        1. –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-100 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ embedding
        2. –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ —Ñ–∏—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        3. –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ LTR –º–æ–¥–µ–ª—å
        4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K
        """

        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (top-100)
        candidates = super().search_similar(query, top_k=min(100, top_k * 10))

        if not candidates:
            return []

        # –®–∞–≥ 2: –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏—á–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        features_list = []
        for news in candidates:
            features = self.calculate_features(query, news)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            features_list.append([features[col] for col in self.feature_columns])

        # –®–∞–≥ 3: –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ LTR –º–æ–¥–µ–ª—å
        X = np.array(features_list)
        ltr_scores = self.ltr_model.predict(X)

        # –®–∞–≥ 4: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ LTR-—Å–∫–æ—Ä—É
        for i, news in enumerate(candidates):
            news['ltr_score'] = float(ltr_scores[i])

        candidates.sort(key=lambda x: x['ltr_score'], reverse=True)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K
        return candidates[:top_k]


def test_ltr_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ —Å LTR"""

    print("=" * 70)
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LTR –ø–æ–∏—Å–∫–∞")
    print("=" * 70)
    print()

    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É —Å LTR
    rag_ltr = LTRNewsRAGSystem()

    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–°–±–µ—Ä–±–∞–Ω–∫",
        "–¶–ë –ø–æ–≤—ã—Å–∏–ª —Å—Ç–∞–≤–∫—É",
        "–∏–ø–æ—Ç–µ–∫–∞",
    ]

    for query in test_queries:
        print(f"\nüîç –ó–∞–ø—Ä–æ—Å: '{query}'")
        print("-" * 70)

        results = rag_ltr.search_similar(query, top_k=5)

        for i, news in enumerate(results, 1):
            print(f"\n{i}. {news['title'][:80]}...")
            print(f"   LTR Score: {news['ltr_score']:.4f}")
            print(f"   Embedding: {news.get('similarity', 0):.4f}")
            print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {news.get('source', 'N/A')}")

    print("\n" + "=" * 70)
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("=" * 70)


if __name__ == "__main__":
    test_ltr_search()
